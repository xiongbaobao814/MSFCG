Use GPU: cuda:0
>>>>>>>start training : ETTh2_MSFCGNN2_ftETTh2_slM_pl96_192>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8353
val 2689
test 2689
Traceback (most recent call last):
  File "/home/shilin/code/MSFCG/run.py", line 127, in <module>
    exp.train(setting)
  File "/home/shilin/code/MSFCG/exp/exp_main.py", line 137, in train
    outputs = self.model(batch_x, batch_x_mark)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shilin/code/MSFCG/models/MSFCGNN2.py", line 254, in forward
    x_enc = self.enc_embedding(x_enc, x_mark_enc)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shilin/code/MSFCG/layers/Embed.py", line 114, in forward
    x = self.value_embedding(x) + self.temporal_embedding(x_mark) + self.position_embedding(x)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shilin/code/MSFCG/layers/Embed.py", line 36, in forward
    x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 308, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/shilin/miniconda3/envs/python310/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 301, in _conv_forward
    return F.conv1d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),
RuntimeError: Given groups=1, weight of size [64, 7, 3], expected input[32, 64, 98] to have 7 channels, but got 64 channels instead
